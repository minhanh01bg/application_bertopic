{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 0:  ******D đ****t cụ mấy thằng ptit ở malibu giờ đi ngủ ngậm mồm vào tắt âm đê ko ngủ để ngkhac ngủ, lớn rồi ý thức lên ttnv\n",
      "text 1:  Ngày mai, tôi sẽ đi học\n",
      "text 2:  kiếm mập_mờ malibu gấp lạnh lắm rồiiiiiii\n",
      "pos_tag_of_text 0:  [('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('D', 'Np'), ('đ', 'Ny'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('t', 'V'), ('cụ', 'N'), ('mấy', 'L'), ('thằng', 'Nc'), ('ptit', 'N'), ('ở', 'E'), ('malibu', 'N'), ('giờ', 'N'), ('đi', 'V'), ('ngủ', 'V'), ('ngậm mồm', 'V'), ('vào', 'E'), ('tắt âm', 'N'), ('đê', 'N'), ('ko', 'N'), ('ngủ', 'V'), ('để', 'E'), ('ngkhac', 'V'), ('ngủ', 'V'), (',', 'CH'), ('lớn', 'A'), ('rồi', 'C'), ('ý thức', 'V'), ('lên', 'V'), ('ttnv', 'M')]\n",
      "pos_tag_of_text 1:  [('Ngày mai', 'N'), (',', 'CH'), ('tôi', 'P'), ('sẽ', 'R'), ('đi', 'V'), ('học', 'V')]\n",
      "pos_tag_of_text 2:  [('kiếm', 'V'), ('mập_mờ', 'N'), ('malibu', 'V'), ('gấp', 'V'), ('lạnh', 'A'), ('lắm', 'R'), ('rồiiiiiii', 'M')]\n",
      "pos_tagging_drop text 0:  D đ t cụ thằng ptit malibu giờ đi ngủ ngậm mồm tắt âm đê ko ngủ ngkhac ngủ lớn ý thức lên\n",
      "pos_tagging_drop text 1:  Ngày mai tôi đi học\n",
      "pos_tagging_drop text 2:  kiếm mập_mờ malibu gấp lạnh\n",
      "remove_syntax_in_word text 0:  cụ mấy thằng ptit ở malibu giờ đi ngủ ngậm mồm vào tắt âm đê ko ngủ để ngkhac ngủ, lớn rồi ý thức lên ttnv\n",
      "remove_syntax_in_word text 1:  Ngày mai, tôi sẽ đi học\n",
      "remove_syntax_in_word text 2:  kiếm mập_mờ malibu gấp lạnh lắm rồiiiiiii\n",
      "scale_word_summary text 0:  ******D đ****t cụ mấy thằng ptit ở malibu giờ đi ngủ ngậm mồm vào tắt âm đê không ngủ để người_khác ngủ, lớn rồi ý thức lên thứ_thự_nguyện_vọng\n",
      "scale_word_summary text 1:  Ngày mai, tôi sẽ đi học\n",
      "scale_word_summary text 2:  kiếm mập_mờ malibu gấp lạnh lắm rồiiiiiii\n"
     ]
    }
   ],
   "source": [
    "import underthesea\n",
    "import re\n",
    "import json\n",
    "text = '******D đ****t cụ mấy thằng ptit ở malibu giờ đi ngủ ngậm mồm vào tắt âm đê ko ngủ để ngkhac ngủ, lớn rồi ý thức lên ttnv'\n",
    "text1 ='Ngày mai, tôi sẽ đi học'\n",
    "text2 = 'kiếm mập_mờ malibu gấp lạnh lắm rồiiiiiii'\n",
    "print('text 0: ',text)\n",
    "print('text 1: ',text1)\n",
    "print('text 2: ',text2)\n",
    "\n",
    "print('pos_tag_of_text 0: ',underthesea.pos_tag(text))\n",
    "print('pos_tag_of_text 1: ',underthesea.pos_tag(text1))\n",
    "print('pos_tag_of_text 2: ',underthesea.pos_tag(text2))\n",
    "def pos_tagging_drop(text):\n",
    "    list_dict = underthesea.pos_tag(text)\n",
    "    list_word = []\n",
    "    for i,val in list_dict:\n",
    "        if val  not in ['CH', 'L', 'M', 'R', 'E', 'C', 'I', 'T', 'X', 'Y']:\n",
    "            list_word.append(i)\n",
    "    return ' '.join(list_word)\n",
    "\n",
    "print('pos_tagging_drop text 0: ',pos_tagging_drop(text))\n",
    "print('pos_tagging_drop text 1: ',pos_tagging_drop(text1))\n",
    "print('pos_tagging_drop text 2: ',pos_tagging_drop(text2))\n",
    "def remove_syntax_in_word(text):\n",
    "    text = re.sub(r'\\w*[\\+\\-\\/\\*\\%\\=\\(\\)\\[\\]\\{\\}]\\w*\\s?', '', text).strip()\n",
    "    return text\n",
    "\n",
    "print('remove_syntax_in_word text 0: ',remove_syntax_in_word(text))\n",
    "print('remove_syntax_in_word text 1: ',remove_syntax_in_word(text1))\n",
    "print('remove_syntax_in_word text 2: ',remove_syntax_in_word(text2))\n",
    "def scale_word_summary(text):\n",
    "    with open('./data_test/word_summary.json', 'r', encoding='utf-8') as f:\n",
    "        word_summary = json.load(f)\n",
    "    text = text.split()\n",
    "    for i, word in enumerate(text):\n",
    "        for key, value in word_summary.items():\n",
    "            key = key.split('|')\n",
    "            if word in key:\n",
    "                text[i] = re.sub(r'\\s+','_',value)\n",
    "    return ' '.join(text)\n",
    "\n",
    "print('scale_word_summary text 0: ',scale_word_summary(text))\n",
    "print('scale_word_summary text 1: ',scale_word_summary(text1)) \n",
    "print('scale_word_summary text 2: ',scale_word_summary(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chuoi tieng Viet viet sai chinh ta , tinh viet nham thanh tinh .\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "\n",
    "def normalize_vietnamese_text(input_text):\n",
    "    # Chuyển đổi ký tự có dấu sang ký tự không dấu\n",
    "    normalized_text = unidecode(input_text)\n",
    "\n",
    "    # Tách từ tiếng Việt và đánh nhãn từ loại\n",
    "    words, pos_tags = ViPosTagger.postagging(ViTokenizer.tokenize(normalized_text))\n",
    "\n",
    "    # Sửa chính tả cho mỗi từ (đây là một ví dụ đơn giản, bạn có thể mở rộng để sử dụng một thư viện kiểm tra chính tả)\n",
    "    corrected_tokens = [word if pos.startswith('N') else word for word, pos in zip(words, pos_tags)]\n",
    "\n",
    "    # Kết hợp lại thành chuỗi sau khi sửa chính tả\n",
    "    normalized_text = ' '.join(corrected_tokens)\n",
    "\n",
    "    return normalized_text\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "input_text = \"Chuỗi tiếng Việt viết sai chính tả, tĩnh viết nhầm thành tỉnh.\"\n",
    "normalized_text = normalize_vietnamese_text(input_text)\n",
    "print(normalized_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
