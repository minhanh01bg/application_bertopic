{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 0:  ******D ƒë****t c·ª• m·∫•y th·∫±ng ptit ·ªü malibu gi·ªù ƒëi ng·ªß ng·∫≠m m·ªìm v√†o t·∫Øt √¢m ƒë√™ ko ng·ªß ƒë·ªÉ ngkhac ng·ªß, l·ªõn r·ªìi √Ω th·ª©c l√™n ttnv\n",
      "text 1:  Ng√†y mai, t√¥i s·∫Ω ƒëi h·ªçc\n",
      "text 2:  ki·∫øm m·∫≠p_m·ªù malibu g·∫•p l·∫°nh l·∫Øm r·ªìiiiiiii\n",
      "pos_tag_of_text 0:  [('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('D', 'Np'), ('ƒë', 'Ny'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('*', 'CH'), ('t', 'V'), ('c·ª•', 'N'), ('m·∫•y', 'L'), ('th·∫±ng', 'Nc'), ('ptit', 'N'), ('·ªü', 'E'), ('malibu', 'N'), ('gi·ªù', 'N'), ('ƒëi', 'V'), ('ng·ªß', 'V'), ('ng·∫≠m m·ªìm', 'V'), ('v√†o', 'E'), ('t·∫Øt √¢m', 'N'), ('ƒë√™', 'N'), ('ko', 'N'), ('ng·ªß', 'V'), ('ƒë·ªÉ', 'E'), ('ngkhac', 'V'), ('ng·ªß', 'V'), (',', 'CH'), ('l·ªõn', 'A'), ('r·ªìi', 'C'), ('√Ω th·ª©c', 'V'), ('l√™n', 'V'), ('ttnv', 'M')]\n",
      "pos_tag_of_text 1:  [('Ng√†y mai', 'N'), (',', 'CH'), ('t√¥i', 'P'), ('s·∫Ω', 'R'), ('ƒëi', 'V'), ('h·ªçc', 'V')]\n",
      "pos_tag_of_text 2:  [('ki·∫øm', 'V'), ('m·∫≠p_m·ªù', 'N'), ('malibu', 'V'), ('g·∫•p', 'V'), ('l·∫°nh', 'A'), ('l·∫Øm', 'R'), ('r·ªìiiiiiii', 'M')]\n",
      "pos_tagging_drop text 0:  D ƒë t c·ª• th·∫±ng ptit malibu gi·ªù ƒëi ng·ªß ng·∫≠m m·ªìm t·∫Øt √¢m ƒë√™ ko ng·ªß ngkhac ng·ªß l·ªõn √Ω th·ª©c l√™n\n",
      "pos_tagging_drop text 1:  Ng√†y mai t√¥i ƒëi h·ªçc\n",
      "pos_tagging_drop text 2:  ki·∫øm m·∫≠p_m·ªù malibu g·∫•p l·∫°nh\n",
      "remove_syntax_in_word text 0:  c·ª• m·∫•y th·∫±ng ptit ·ªü malibu gi·ªù ƒëi ng·ªß ng·∫≠m m·ªìm v√†o t·∫Øt √¢m ƒë√™ ko ng·ªß ƒë·ªÉ ngkhac ng·ªß, l·ªõn r·ªìi √Ω th·ª©c l√™n ttnv\n",
      "remove_syntax_in_word text 1:  Ng√†y mai, t√¥i s·∫Ω ƒëi h·ªçc\n",
      "remove_syntax_in_word text 2:  ki·∫øm m·∫≠p_m·ªù malibu g·∫•p l·∫°nh l·∫Øm r·ªìiiiiiii\n",
      "scale_word_summary text 0:  ******D ƒë****t c·ª• m·∫•y th·∫±ng ptit ·ªü malibu gi·ªù ƒëi ng·ªß ng·∫≠m m·ªìm v√†o t·∫Øt √¢m ƒë√™ kh√¥ng ng·ªß ƒë·ªÉ ng∆∞·ªùi_kh√°c ng·ªß, l·ªõn r·ªìi √Ω th·ª©c l√™n th·ª©_th·ª±_nguy·ªán_v·ªçng\n",
      "scale_word_summary text 1:  Ng√†y mai, t√¥i s·∫Ω ƒëi h·ªçc\n",
      "scale_word_summary text 2:  ki·∫øm m·∫≠p_m·ªù malibu g·∫•p l·∫°nh l·∫Øm r·ªìiiiiiii\n"
     ]
    }
   ],
   "source": [
    "import underthesea\n",
    "import re\n",
    "import json\n",
    "text = '******D ƒë****t c·ª• m·∫•y th·∫±ng ptit ·ªü malibu gi·ªù ƒëi ng·ªß ng·∫≠m m·ªìm v√†o t·∫Øt √¢m ƒë√™ ko ng·ªß ƒë·ªÉ ngkhac ng·ªß, l·ªõn r·ªìi √Ω th·ª©c l√™n ttnv'\n",
    "text1 ='Ng√†y mai, t√¥i s·∫Ω ƒëi h·ªçc'\n",
    "text2 = 'ki·∫øm m·∫≠p_m·ªù malibu g·∫•p l·∫°nh l·∫Øm r·ªìiiiiiii'\n",
    "print('text 0: ',text)\n",
    "print('text 1: ',text1)\n",
    "print('text 2: ',text2)\n",
    "\n",
    "print('pos_tag_of_text 0: ',underthesea.pos_tag(text))\n",
    "print('pos_tag_of_text 1: ',underthesea.pos_tag(text1))\n",
    "print('pos_tag_of_text 2: ',underthesea.pos_tag(text2))\n",
    "def pos_tagging_drop(text):\n",
    "    list_dict = underthesea.pos_tag(text)\n",
    "    list_word = []\n",
    "    for i,val in list_dict:\n",
    "        if val  not in ['CH', 'L', 'M', 'R', 'E', 'C', 'I', 'T', 'X', 'Y']:\n",
    "            list_word.append(i)\n",
    "    return ' '.join(list_word)\n",
    "\n",
    "print('pos_tagging_drop text 0: ',pos_tagging_drop(text))\n",
    "print('pos_tagging_drop text 1: ',pos_tagging_drop(text1))\n",
    "print('pos_tagging_drop text 2: ',pos_tagging_drop(text2))\n",
    "def remove_syntax_in_word(text):\n",
    "    text = re.sub(r'\\w*[\\+\\-\\/\\*\\%\\=\\(\\)\\[\\]\\{\\}]\\w*\\s?', '', text).strip()\n",
    "    return text\n",
    "\n",
    "print('remove_syntax_in_word text 0: ',remove_syntax_in_word(text))\n",
    "print('remove_syntax_in_word text 1: ',remove_syntax_in_word(text1))\n",
    "print('remove_syntax_in_word text 2: ',remove_syntax_in_word(text2))\n",
    "def scale_word_summary(text):\n",
    "    with open('./data_test/word_summary.json', 'r', encoding='utf-8') as f:\n",
    "        word_summary = json.load(f)\n",
    "    text = text.split()\n",
    "    for i, word in enumerate(text):\n",
    "        for key, value in word_summary.items():\n",
    "            key = key.split('|')\n",
    "            if word in key:\n",
    "                text[i] = re.sub(r'\\s+','_',value)\n",
    "    return ' '.join(text)\n",
    "\n",
    "print('scale_word_summary text 0: ',scale_word_summary(text))\n",
    "print('scale_word_summary text 1: ',scale_word_summary(text1)) \n",
    "print('scale_word_summary text 2: ',scale_word_summary(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_word_hash text 1:  <G√≥c nh·ªØng tr√°i t‚ù§m ƒëi l·∫°c>\n",
      "Xin ch√†o c√°c PTITers, m√¨nh l√† g∆°n AOF, t·ªëi h√¥m ch√†o t√¢n The Railway c·ªßa AOF th√¨ m√¨nh th·∫•y c√≥ 1 b·∫°n PTIT ƒë·∫øn v√† c√≥ ch·ª•p m·∫•y ·∫£nh 0,5x trong l√∫c ƒë·ª£i DJ ch∆°i nh·∫°c. Nh∆∞ng m√† l√∫c v·ªÅ v√¨ m·ªçi ng∆∞·ªùi chen l·∫•n, x√¥ ƒë·∫©y qu√° n√™n m√¨nh kh√¥ng k·ªãp xin ·∫£nh. M√¨nh mong up l√™n ƒë√¢y c√≥ th·ªÉ t√¨m ƒë∆∞·ª£c b·∫°n v√† xin m·∫•y t·∫•m ·∫£nh l√†m k·ª∑ ni·ªám ·∫°\n",
      "\n",
      "m√¨nh c√≥ g·∫∑p m·ªôt b·∫°n n·ªØ tham gia s·ª± ki·ªán ITFest tr√™n HoLa r·∫•t cute nh∆∞ng ch∆∞a k·ªãp xin in4 th√¨ b·∫°n ƒëi m·∫•t r·ªìi. B·∫°n √Ω ng∆∞·ªùi nh·ªè nh·∫Øn , m·∫∑c √°o tr·∫Øng , c·∫ßm √¥ ƒë·ª©ng b√™n tr√™n l·ªách tr√°i h∆∞·ªõng v·ªÅ ph√≠a s√¢n theo m√¨nh quan s√°t l√† b·∫°n d√πng . B·∫°n √Ω ƒë·ª©ng c√πng m·ªôt ch·ªã kh√°c m·∫∑c √°o ƒëen h·ªçc bk. M√¨nh th·∫•y b·∫°n v·ª´a c·∫ßm √¥ v·ª´a ch·ª•p h√¨nh kh√° kh√≥ n√™n c√≥ gi√∫p b·∫°n c·∫ßm √¥ 1 ch√∫t x√≠u .N·∫øu b·∫°n th·∫•y ƒë∆∞·ª£c cfs n√†y v√† c√≥ th·ªÉ cho m√¨nh xin in4 th√¨ b·∫°n cmt cho m√¨nh v·ªõi ho·∫∑c b·∫°n stt n√†y ƒë∆∞·ª£c k , m√¨nh s·∫Ω ch·ªß ƒë·ªông k·∫øt b·∫°n v·ªõi b·∫°n.\n",
      "\n",
      "-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\n",
      "üí• G·ª¨I CFS /.PTIT Confessions Offical ptitcfs.hanoi@gmail.com\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "<G√≥c nh·ªØng tr√°i t‚ù§m ƒëi l·∫°c>\n",
    "#cfs17330\n",
    "Xin ch√†o c√°c PTITers, m√¨nh l√† g∆°n AOF, t·ªëi h√¥m ch√†o t√¢n The Railway c·ªßa AOF th√¨ m√¨nh th·∫•y c√≥ 1 b·∫°n PTIT ƒë·∫øn v√† c√≥ ch·ª•p m·∫•y ·∫£nh 0,5x trong l√∫c ƒë·ª£i DJ ch∆°i nh·∫°c. Nh∆∞ng m√† l√∫c v·ªÅ v√¨ m·ªçi ng∆∞·ªùi chen l·∫•n, x√¥ ƒë·∫©y qu√° n√™n m√¨nh kh√¥ng k·ªãp xin ·∫£nh. M√¨nh mong up l√™n ƒë√¢y c√≥ th·ªÉ t√¨m ƒë∆∞·ª£c b·∫°n v√† xin m·∫•y t·∫•m ·∫£nh l√†m k·ª∑ ni·ªám ·∫°\n",
    "\n",
    "#cfs17331\n",
    "H√¥m* 12/11 m√¨nh c√≥ g·∫∑p m·ªôt b·∫°n n·ªØ tham gia s·ª± ki·ªán ITFest tr√™n HoLa r·∫•t cute nh∆∞ng ch∆∞a k·ªãp xin in4 th√¨ b·∫°n ƒëi m·∫•t r·ªìi. B·∫°n √Ω ng∆∞·ªùi nh·ªè nh·∫Øn , m·∫∑c √°o tr·∫Øng , c·∫ßm √¥ ƒë·ª©ng b√™n tr√™n l·ªách tr√°i h∆∞·ªõng v·ªÅ ph√≠a s√¢n kh·∫•u( theo m√¨nh quan s√°t l√† b·∫°n d√πng samsung). B·∫°n √Ω ƒë·ª©ng c√πng m·ªôt ch·ªã kh√°c m·∫∑c √°o ƒëen h·ªçc bk. M√¨nh th·∫•y b·∫°n v·ª´a c·∫ßm √¥ v·ª´a ch·ª•p h√¨nh kh√° kh√≥ n√™n c√≥ gi√∫p b·∫°n c·∫ßm √¥ 1 ch√∫t x√≠u .N·∫øu b·∫°n th·∫•y ƒë∆∞·ª£c cfs n√†y v√† c√≥ th·ªÉ cho m√¨nh xin in4 th√¨ b·∫°n cmt cho m√¨nh v·ªõi nha( ho·∫∑c b·∫°n stt n√†y ƒë∆∞·ª£c k ·∫°), m√¨nh s·∫Ω ch·ªß ƒë·ªông k·∫øt b·∫°n v·ªõi b·∫°n.\n",
    "\n",
    "-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\n",
    "üí• G·ª¨I CFS T·∫†I: http://bit.ly/ptitcfshn\n",
    "PTIT Confessions Offical (since 2013)\n",
    "Email: ptitcfs.hanoi@gmail.com\n",
    "\n",
    "#ptitconfessions #ptitcfs #ptitcogivui #sinhvienptit #congdongptit #ptitmaidinh\n",
    "\"\"\"\n",
    "def remove_special_character_in_word(text):\n",
    "    text = re.sub(r'\\w+[\\+\\-\\/\\*\\%\\=\\:\\(\\)\\[\\]\\{\\}]\\w+\\s?', '', text).strip()\n",
    "    text = re.sub(r'[\\#\\+\\-\\/\\*\\%\\=\\:\\(\\)\\[\\]\\{\\}]\\w+\\s?', '', text).strip()\n",
    "    text = re.sub(r'\\w+[\\+\\-\\/\\*\\%\\=\\:\\(\\)\\[\\]\\{\\}]\\s?', '', text).strip()\n",
    "    return text\n",
    "\n",
    "# print('remove_word_hash text 0: ',remove_word_hash(text))\n",
    "print('remove_word_hash text 1: ',remove_special_character_in_word(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói gi√° tr·ªã:\n",
      "Name\n",
      "B    3\n",
      "C    2\n",
      "A    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "S·ªë l·∫ßn xu·∫•t hi·ªán ƒë∆∞·ª£c s·∫Øp x·∫øp theo ch·ªâ s·ªë:\n",
      "Name\n",
      "A    1\n",
      "B    3\n",
      "C    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# T·∫°o DataFrame gi·∫£ ƒë·ªãnh\n",
    "data = {'Name': ['C','C', 'B','B','B','A']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói gi√° tr·ªã trong c·ªôt 'Name'\n",
    "value_counts = df['Name'].value_counts()\n",
    "\n",
    "# S·∫Øp x·∫øp theo ch·ªâ s·ªë (t√™n)\n",
    "sorted_counts = value_counts.sort_index()\n",
    "\n",
    "print(\"S·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói gi√° tr·ªã:\")\n",
    "print(value_counts)\n",
    "\n",
    "print(\"\\nS·ªë l·∫ßn xu·∫•t hi·ªán ƒë∆∞·ª£c s·∫Øp x·∫øp theo ch·ªâ s·ªë:\")\n",
    "print(sorted_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 2:  th·ªùi gian s·∫Øp h·∫øt r·ªìi ƒëƒÉng k√Ω s·ªõm c√°c em nh√© nh·ªØng sv n√†o ƒë√£ ƒëƒÉng k√Ω xong th√¨ n·ªôp h·ªì s∆° b·∫£n c·ª©ng v·ªÅ √¥ s·ªë 6 vƒÉn ph√≤ng giao d·ªãch 1 c·ª≠a cho c√¥ nh√© thanks all  daotaoptiteduvn th√¥ng b√°o k·∫ø ho·∫°ch t·ªï ch·ª©c thi c·∫•p ch·ª©ng ch·ªâ toeic qu·ªëc t·∫ø (ƒë·ª£t thi th√°ng 12/2023)  pika chuss‚Äéd20 ptit h√† n·ªôi 23 th√°ng 10 l√∫c 09:51 ¬∑\n"
     ]
    }
   ],
   "source": [
    "txt = \"text 2:  th·ªùi gian s·∫Øp h·∫øt r·ªìi ƒëƒÉng k√Ω s·ªõm c√°c em nh√© nh·ªØng sv n√†o ƒë√£ ƒëƒÉng k√Ω xong th√¨ n·ªôp h·ªì s∆° b·∫£n c·ª©ng v·ªÅ √¥ s·ªë 6 vƒÉn ph√≤ng giao d·ªãch 1 c·ª≠a cho c√¥ nh√© thanks all  daotaoptiteduvn th√¥ng b√°o k·∫ø ho·∫°ch t·ªï ch·ª©c thi c·∫•p ch·ª©ng ch·ªâ toeic qu·ªëc t·∫ø (ƒë·ª£t thi th√°ng 12/2023)  pika chuss‚Äéd20 ptit h√† n·ªôi 23 th√°ng 10 l√∫c 09:51 ¬∑\"\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 0:  th·∫ø l√† c≈©ng xong xu√¥i nh·∫≠p h·ªçc r·ªìi nh·ªâ mini game nh·ªè kh√¥ng  ƒë∆°n gi·∫£n th√¥i cmt b·∫•t c·ª© ƒëi·ªÅu g√¨ b·∫°n th·∫•y ·∫•n t∆∞·ª£ng nh·∫•t trong 2 ng√†y nh·∫≠p h·ªçc ho·∫∑c ƒë∆°n gi·∫£n l√† c·∫£m nh·∫≠n c·ªßa b·∫°n ƒë√≠nh k√®m ·∫£nh\\video th√¨ c√†ng t·ªët  1xem th√™m cmt nhi·ªÅu like nh·∫•t ch·ªß cmt s·∫Ω ƒë∆∞·ª£c ‚Äúƒë·∫∑c quy·ªÅn‚Äù ƒëƒÉng b√†i kh√¥ng c·∫ßn ki·ªÉm duy·ªát trong gr d22 k√®m m√≥c kho√° ƒë·ªôc quy·ªÅn c·ªßa t√¥i y√™u ptit m√¨nh s·∫Ω ƒë√≥ng cmt v√†o 20h ng√†y 13/10  welcome d22 #toiyeuptit\n"
     ]
    }
   ],
   "source": [
    "txt = \"text 0:  th·∫ø l√† c≈©ng xong xu√¥i nh·∫≠p h·ªçc r·ªìi nh·ªâ mini game nh·ªè kh√¥ng  ƒë∆°n gi·∫£n th√¥i cmt b·∫•t c·ª© ƒëi·ªÅu g√¨ b·∫°n th·∫•y ·∫•n t∆∞·ª£ng nh·∫•t trong 2 ng√†y nh·∫≠p h·ªçc ho·∫∑c ƒë∆°n gi·∫£n l√† c·∫£m nh·∫≠n c·ªßa b·∫°n ƒë√≠nh k√®m ·∫£nh\\\\video th√¨ c√†ng t·ªët  1xem th√™m cmt nhi·ªÅu like nh·∫•t ch·ªß cmt s·∫Ω ƒë∆∞·ª£c ‚Äúƒë·∫∑c quy·ªÅn‚Äù ƒëƒÉng b√†i kh√¥ng c·∫ßn ki·ªÉm duy·ªát trong gr d22 k√®m m√≥c kho√° ƒë·ªôc quy·ªÅn c·ªßa t√¥i y√™u ptit m√¨nh s·∫Ω ƒë√≥ng cmt v√†o 20h ng√†y 13/10  welcome d22 #toiyeuptit\"\n",
    "print(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
